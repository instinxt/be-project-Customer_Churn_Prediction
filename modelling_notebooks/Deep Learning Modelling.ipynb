{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "random_state = 10\n",
    "np.random.seed(random_state)\n",
    "tf.random.set_seed(random_state)\n",
    "\n",
    "\n",
    "# Matplotlib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "# display plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "### sns.set_style('darkgrid')\n",
    "\n",
    "# store elements as dictionary keys and their counts as dictionary values\n",
    "from collections import Counter\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function for creating model pipelines - imblearn\n",
    "from imblearn.pipeline import make_pipeline as imbl_pipe\n",
    "\n",
    "# Over-sampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are runnig \"Dark Reader\" on Chrome,install \"jupyterthemes \n",
    "#  and run these lines so the legends and axes become visible\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n",
    "\n",
    "# To reset default matplotlib rcParams\n",
    "## jtplot.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Analytical Base Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "abt = pd.read_csv(\"../Resources/analytical_base_table.csv\")\n",
    "print(f\"Dataframe dimensions: {abt.shape}\")\n",
    "abt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by splitting our dataframe into separate objects:\n",
    "\n",
    "* **y** for the target varibale\n",
    "\n",
    "* **X** for the input features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dataframe into separate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Object for target variable\n",
    "y = abt.Exited\n",
    "\n",
    "# object for input features\n",
    "X = abt.drop(['Exited'], axis=1)\n",
    "\n",
    "# display shapes of X and y\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List numerical features\n",
    "num_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography', 'Gender']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List categorical features\n",
    "cat_columns = X.select_dtypes(include='object').columns.tolist()\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_count(a):\n",
    "    counter=Counter(a)\n",
    "    kv=[list(counter.keys()),list(counter.values())]\n",
    "    dff = pd.DataFrame(np.array(kv).T, columns=['Exited','Count'])\n",
    "    dff['Count'] = dff['Count'].astype('int64')\n",
    "    dff['%'] = round(dff['Count'] / a.shape[0] * 100, 2)\n",
    "    return dff.sort_values('Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>Count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7963</td>\n",
       "      <td>79.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2037</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exited  Count      %\n",
       "1       0   7963  79.63\n",
       "0       1   2037  20.37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue with splitting our data into separate training and test sets.\n",
    "\n",
    "* 30% of observations will be set aside for the test set\n",
    "\n",
    "* the rest, 70%, will be used as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 3000 7000 3000\n"
     ]
    }
   ],
   "source": [
    "random_state = 10\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=abt.Exited)\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7000 entries, 8061 to 4741\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      7000 non-null   int64  \n",
      " 1   Geography        7000 non-null   object \n",
      " 2   Gender           7000 non-null   object \n",
      " 3   Age              7000 non-null   int64  \n",
      " 4   Tenure           7000 non-null   int64  \n",
      " 5   Balance          7000 non-null   float64\n",
      " 6   NumOfProducts    7000 non-null   int64  \n",
      " 7   HasCrCard        7000 non-null   int64  \n",
      " 8   IsActiveMember   7000 non-null   int64  \n",
      " 9   EstimatedSalary  7000 non-null   float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 601.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical data and encode categorical data\n",
    "Construct a pre-processing pipeline from the given transformers: MinMaxScaler and OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of indexes from the list of column names\n",
    "\n",
    "Need to be numeric not string to specify columns name in column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "num_features = [] \n",
    "\n",
    "for i in num_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    num_features.append(location)\n",
    "print(num_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "\n",
    "for i in cat_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    cat_features.append(location)\n",
    "print(cat_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                ('onehotencoder', OneHotEncoder(sparse=False),\n",
       "                                 [1, 2])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define column transformer\n",
    "# Need to be numeric not string to specify columns name \n",
    "preprocess = make_column_transformer(\n",
    "    (MinMaxScaler(), num_features),\n",
    "    (OneHotEncoder(sparse=False), cat_features)\n",
    ")\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess X_train to get its shape for Keras pipeline\n",
    "X_train_pp = preprocess.fit_transform(X_train)\n",
    "\n",
    "print(X_train_pp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pre-proces our labels we will use scikit-learn LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_lb = lb.fit_transform(y_train)\n",
    "y_test_lb = lb.transform(y_test)\n",
    "y_train_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 1) (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_lb.shape, y_test_lb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Keras Wrappers for the Scikit-Learn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining Keras model creator function\n",
    "# def create_model(optimizer=\"adam\", dropout=0.1, n_features=X_train_pp.shape[1], n_units=64):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(n_units, activation='relu', input_shape=(n_features,)))\n",
    "#     model.add(Dropout(dropout), )\n",
    "#     model.add(Dense(n_units, activation='relu'))\n",
    "#     model.add(Dropout(dropout), )          \n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the Scikit-Learn classifier interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import model build function \"create_model\"from the script \"keras_model.py\"\n",
    "import keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sklearn-like classifier\n",
    "keras_clf = KerasClassifier(build_fn=keras_model.create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model Pipeline with SMOTE\n",
    "\n",
    "* We are going to use the Pipeline from the imblearn package in place of scikit-learn Pipeline.\n",
    "\n",
    "* It takes care automatically to re-sample when called fit() on the pipeline, and does not re-sample test data (when called transform() or predict())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 2])])),\n",
       "                ('smote', SMOTE(random_state=10)),\n",
       "                ('kerasclassifier',\n",
       "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000002221B33DC48>)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model with pipeline\n",
    "model = imbl_pipe(preprocess,\n",
    "                  SMOTE(sampling_strategy='auto', random_state=random_state),\n",
    "                  keras_clf)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                    [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                   ('onehotencoder', OneHotEncoder(sparse=False),\n",
       "                                    [1, 2])])),\n",
       "  ('smote', SMOTE(random_state=10)),\n",
       "  ('kerasclassifier',\n",
       "   <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x2221b33dc48>)],\n",
       " 'verbose': False,\n",
       " 'columntransformer': ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                  [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                 ('onehotencoder', OneHotEncoder(sparse=False),\n",
       "                                  [1, 2])]),\n",
       " 'smote': SMOTE(random_state=10),\n",
       " 'kerasclassifier': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x2221b33dc48>,\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('minmaxscaler',\n",
       "   MinMaxScaler(),\n",
       "   [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "  ('onehotencoder', OneHotEncoder(sparse=False), [1, 2])],\n",
       " 'columntransformer__verbose': False,\n",
       " 'columntransformer__minmaxscaler': MinMaxScaler(),\n",
       " 'columntransformer__onehotencoder': OneHotEncoder(sparse=False),\n",
       " 'columntransformer__minmaxscaler__copy': True,\n",
       " 'columntransformer__minmaxscaler__feature_range': (0, 1),\n",
       " 'columntransformer__onehotencoder__categories': 'auto',\n",
       " 'columntransformer__onehotencoder__drop': None,\n",
       " 'columntransformer__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__onehotencoder__handle_unknown': 'error',\n",
       " 'columntransformer__onehotencoder__sparse': False,\n",
       " 'smote__k_neighbors': 5,\n",
       " 'smote__n_jobs': None,\n",
       " 'smote__random_state': 10,\n",
       " 'smote__sampling_strategy': 'auto',\n",
       " 'kerasclassifier__verbose': 0,\n",
       " 'kerasclassifier__build_fn': <function keras_model.create_model(optimizer='adam', dropout=0.1, n_features=13, n_units=64)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for Keras classifier\n",
    "\n",
    "param_grid = {\n",
    "    'kerasclassifier__epochs': [10],\n",
    "    'kerasclassifier__n_units': [64, 128, 100],\n",
    "    #'kerasclassifier__init': [ 'uniform', 'zeros', 'normal', ], \n",
    "    #'kerasclassifier__batch_size':[4, 16, 32],\n",
    "    #'kerasclassifier__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
    "    'kerasclassifier__dropout': [0.5, 0.3, 0.2, 0.1, 0],\n",
    "    'kerasclassifier__verbose': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, cv= 5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                                         MinMaxScaler(),\n",
       "                                                                         [0, 3,\n",
       "                                                                          4, 5,\n",
       "                                                                          6, 7,\n",
       "                                                                          8,\n",
       "                                                                          9]),\n",
       "                                                                        ('onehotencoder',\n",
       "                                                                         OneHotEncoder(sparse=False),\n",
       "                                                                         [1,\n",
       "                                                                          2])])),\n",
       "                                       ('smote', SMOTE(random_state=10)),\n",
       "                                       ('kerasclassifier',\n",
       "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000002221B33DC48>)]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'kerasclassifier__dropout': [0.5, 0.3, 0.2, 0.1, 0],\n",
       "                         'kerasclassifier__epochs': [10],\n",
       "                         'kerasclassifier__n_units': [64, 128, 100],\n",
       "                         'kerasclassifier__verbose': [0]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify our Trained Model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8039999961853027  using:\n",
      "{'kerasclassifier__dropout': 0.1, 'kerasclassifier__epochs': 10, 'kerasclassifier__n_units': 100, 'kerasclassifier__verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Score: {grid.best_score_}  using:\\n{grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7897142767906189\n",
      "Testing Data Score: 0.7603333592414856\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "pred = grid.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1805  584]\n",
      " [ 135  476]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76 0.24]\n",
      " [0.22 0.78]]\n"
     ]
    }
   ],
   "source": [
    "# Normalized confusion matrix\n",
    "cm = np.around(cm / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.83      2389\n",
      "           1       0.45      0.78      0.57       611\n",
      "\n",
      "    accuracy                           0.76      3000\n",
      "   macro avg       0.69      0.77      0.70      3000\n",
      "weighted avg       0.83      0.76      0.78      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: \t[0, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
      "Actual Labels: \t\t[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: \\t{list(pred[:10])}\")\n",
    "print(f\"Actual Labels: \\t\\t{list(y_test[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: \t[1]\n",
      "Actual Labels: \t\t[1]\n"
     ]
    }
   ],
   "source": [
    "pred1 = grid.predict(X_test[5:6])\n",
    "print(f\"Predicted classes: \\t{list(pred1)}\")\n",
    "print(f\"Actual Labels: \\t\\t{list(y_test[5:6])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[638, 'France', 'Male', 36, 6, 188455.19, 1, 0, 0, 47031.4]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sh = X_test.iloc[0,:].values.reshape(1,-1)\n",
    "X_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sh = grid.predict(X_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: \t[0]\n",
      "Actual Labels: \t\t[1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: \\t{list(pred_sh)}\")\n",
    "print(f\"Actual Labels: \\t\\t{list(y_test[:1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Trained Model\n",
    "We can save our trained model by saving it into two files:\n",
    "\n",
    "* the first file stores a pickled object of the sklearn pipeline\n",
    "\n",
    "* the second file stores the Keras model using the HDF5 binary format with the extension `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator\n",
    "# This will convert GridSearch object to pipeline object\n",
    "# It will also partially destroyed grid object, \n",
    "# If needed, it could be reran or reconstructed using saved model\n",
    "\n",
    "dl_model_s = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imblearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dl_model_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Keras model first\n",
    "dl_model_s.named_steps['kerasclassifier'].model.save('../models/keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This hack allows us to save the imblearn pipeline\n",
    "dl_model_s.named_steps['kerasclassifier'].model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/imblearn_pipeline.sav']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the pipeline\n",
    "joblib.dump(dl_model_s, '../models/imblearn_pipeline.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not need this pipeline object anymore\n",
    "## del dl_model_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline first\n",
    "dl_model = joblib.load('../models/imblearn_pipeline.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, load the Keras model\n",
    "dl_model.named_steps['kerasclassifier'].model = load_model('../models/keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the loaded model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76033336\n"
     ]
    }
   ],
   "source": [
    "print(dl_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1805  584]\n",
      " [ 135  476]]\n"
     ]
    }
   ],
   "source": [
    "# Classification metrics\n",
    "predl = dl_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predl)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>638</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>188455.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47031.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "7884          638    France   Male   36       6  188455.19              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "7884          0               0          47031.4  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the first X_test record as new data\n",
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = dl_model.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: \t[0]\n",
      "Actual Labels: \t\t[1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: \\t{list(pred_new)}\")\n",
    "print(f\"Actual Labels: \\t\\t{list(y_test[:1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataframe to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[638, 'France', 'Male', 36, 6, 188455.19, 1, 0, 0, 47031.4]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_new1 = dl_model.predict(X_test[:1].to_numpy())\n",
    "pred_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
